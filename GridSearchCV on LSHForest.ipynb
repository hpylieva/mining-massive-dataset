{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.24.223.123:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer,RegexTokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = spark.read.csv(\"listings.csv\",header=True) \n",
    "reviews = spark.read.csv(\"reviews.csv\",header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings = listings.na.fill({'name': ''})\n",
    "names = df_listings.select(col(\"name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"name\", outputCol = \"words\")\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"name\", outputCol=\"words\", \n",
    "                                pattern=\"\\\\W\", toLowercase = False)\n",
    "\n",
    "wordsData = regexTokenizer.transform(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"CleanTokens\")\n",
    "noStopwords = remover.transform(wordsData)\n",
    "customRemover = remover.setStopWords(remover.getStopWords()+[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol = \"CleanTokens\", outputCol = \"rowFeatures\",\n",
    "                      numFeatures = 20)\n",
    "featurizedData = hashingTF.transform(noStopwords)\n",
    "\n",
    "idf = IDF(inputCol = \"rowFeatures\", outputCol = \"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "tfidf = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSerachCV for LSHForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply spark_sklearn.GridSearchCV for LSHForest I have done the next: \n",
    "* Created a new child class of LSHForest (LSHForestExt) in which I've implemented 'score' method. This was required by GridSearchCV to use grid search procedure on LSHF algorithm.\n",
    "\n",
    "\n",
    "* 'score' method computes accuracy to access how close are neighbors found by LSHF to actual neighbours. As actual neighbors I considered ones found with sklearn.neighbors.NearestNeighbors(algorithm='brute'). The accuracy is the number of 'guessed' by LSHF closest neighbors for the particular item out of the total number of neigbours we were searching for. So if LSHF guessed 3 closest neigbours out of 5 requested, then accuracy is 0.6. For a set of items I take mean of accuracies for items in set.\n",
    "\n",
    "\n",
    "* GridSearchCV runs in parallel on the data I pass into 'fit' method. That is why the implemented 'score' method of LSHForestExt is applied to  some subset of the orginal dataset we run GridSearchCV on. But when we apply nearest neighbors algorithm, all items in input set are indexed at the beginning and algorithm produces indeces within the range of input size dataset. That is why to check LSHF's performance, we need to make indeces of input items in LSHF and kNN match, so we need to fit both models on the same data. That is why I fit both models in 'score' method on a small subset (restricted to 500 items, but it's size can be less when a smaller subset is passed into 'score') and then measure LSHF performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LSHForest, NearestNeighbors\n",
    "from spark_sklearn import GridSearchCV\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSHForestExt(LSHForest):\n",
    "    def __init__(self, n_estimators=10, radius=1.0, n_candidates=50,\n",
    "                 n_neighbors=5, min_hash_match=4, radius_cutoff_ratio=.9,\n",
    "                 test_subset_size = 500, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.radius = radius\n",
    "        self.random_state = random_state\n",
    "        self.n_candidates = n_candidates\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.min_hash_match = min_hash_match\n",
    "        self.radius_cutoff_ratio = radius_cutoff_ratio    \n",
    "        self.test_subset_size = test_subset_size\n",
    "      \n",
    "   \n",
    "    def score(self, X):\n",
    "        \"\"\"\n",
    "        Note: score method is called from GridSearch which is executed in parallel \n",
    "            on original data, which is splitted there on train and test. \n",
    "            So we even don't know the exact length of X here\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Test subset. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            Number of 'guessed' by LSHF naighbours compared with neighbours found by \n",
    "            skletrarn.neighbors.NearestNeighbors among total number of neighbours\n",
    "        \"\"\"\n",
    "               \n",
    "        testset_len = min(self.test_subset_size, len(X))\n",
    "        subset = list(X[i] for i in range(testset_len))\n",
    "        nbrs = NearestNeighbors(algorithm='brute', metric='cosine',\n",
    "                        n_neighbors=self.n_neighbors).fit(subset)\n",
    "        self.fit(subset)\n",
    "        real_nbrs = nbrs.kneighbors(subset, return_distance=False)\n",
    "        approx_nbrs = self.kneighbors(subset, return_distance=False)\n",
    "        \n",
    "        accuracy = [np.in1d(approx_nbrs[i], real_nbrs[i]).mean() for i in range(testset_len)]\n",
    "        return np.mean(accuracy)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict kNNs for each row in X\n",
    "        In GridSearchCV this method is applied with best extimator\n",
    "        \"\"\"\n",
    "        return self.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 18556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/random_projection.py:378: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (20 < 32).The dimensionality of the problem will not be reduced.\n",
      "  DataDimensionalityWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for cross validation 96.984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.54378, std: 0.00937, params: {'n_candidates': 10, 'n_estimators': 10},\n",
       " mean: 0.58622, std: 0.01688, params: {'n_candidates': 10, 'n_estimators': 20},\n",
       " mean: 0.66489, std: 0.00793, params: {'n_candidates': 10, 'n_estimators': 50},\n",
       " mean: 0.73333, std: 0.00599, params: {'n_candidates': 10, 'n_estimators': 100},\n",
       " mean: 0.63378, std: 0.01035, params: {'n_candidates': 20, 'n_estimators': 10},\n",
       " mean: 0.75533, std: 0.00785, params: {'n_candidates': 20, 'n_estimators': 20},\n",
       " mean: 0.91022, std: 0.00691, params: {'n_candidates': 20, 'n_estimators': 50},\n",
       " mean: 0.96978, std: 0.00494, params: {'n_candidates': 20, 'n_estimators': 100},\n",
       " mean: 0.93356, std: 0.00300, params: {'n_candidates': 50, 'n_estimators': 10},\n",
       " mean: 0.98133, std: 0.00340, params: {'n_candidates': 50, 'n_estimators': 20},\n",
       " mean: 0.99222, std: 0.00083, params: {'n_candidates': 50, 'n_estimators': 50},\n",
       " mean: 0.99178, std: 0.00191, params: {'n_candidates': 50, 'n_estimators': 100}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "              'n_candidates': [10, 20, 50], #10, 20, 50\n",
    "              'n_estimators': [10, 20, 50, 100] #, 50, 70, 100\n",
    "             }\n",
    "\n",
    "n_neighbors = 3\n",
    "lshf = LSHForestExt(random_state=42, n_neighbors= n_neighbors)\n",
    "clf = GridSearchCV(sc, lshf, parameters)\n",
    "\n",
    "dataset = tfidf.select('features').rdd.flatMap(lambda x: x).collect()\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(dataset)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time spent for cross validation {0:.3f}\".format(end - start))\n",
    "clf.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.9922222821010275\n",
      "\n",
      "Best estimetor {'n_candidates': 50, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score\", clf.best_score_)\n",
    "print(\"\\nBest estimetor\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SparseVector(20, {2: 2.2756, 3: 1.6912, 6: 2.6478, 8: 1.6822, 11: 2.1647, 14: 1.1739, 18: 1.6747}),\n",
       " SparseVector(20, {5: 2.0771, 10: 1.8866, 11: 2.1647, 14: 1.1739, 19: 2.0622}),\n",
       " SparseVector(20, {3: 1.6912, 4: 1.4578, 6: 2.6478, 9: 2.3068, 10: 1.8866, 12: 0.816, 13: 1.4106, 14: 1.1739}),\n",
       " SparseVector(20, {3: 1.6912, 4: 1.4578, 6: 2.6478, 8: 1.6822, 19: 2.0622}),\n",
       " SparseVector(20, {2: 1.1378, 4: 1.4578, 7: 1.7113, 14: 1.1739}),\n",
       " SparseVector(20, {2: 1.1378, 14: 1.1739, 15: 1.4232, 19: 2.0622}),\n",
       " SparseVector(20, {1: 1.3631, 2: 1.1378, 9: 1.1534, 10: 1.8866, 14: 1.1739}),\n",
       " SparseVector(20, {0: 1.3827, 3: 1.6912, 8: 1.6822, 9: 1.1534, 13: 1.4106, 15: 1.4232}),\n",
       " SparseVector(20, {0: 1.3827, 2: 1.1378, 10: 1.8866}),\n",
       " SparseVector(20, {3: 1.6912, 5: 2.0771, 9: 2.3068, 13: 1.4106, 15: 1.4232})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indices of 3 nearest neighbours predicted with LSHF\n",
      "[[    0 13929  5984]\n",
      " [    1 14445 12240]\n",
      " [    2 18407 15740]\n",
      " [    3 18539  3654]\n",
      " [    4  1812    65]\n",
      " [    5 18483 18373]\n",
      " [    6  3466  4876]\n",
      " [ 2452     7  4714]\n",
      " [ 4025     8 11941]\n",
      " [    9  4844   743]]\n",
      "\n",
      "Distances from each of 3 nearest neighbours predicted with LSHF\n",
      "[[0.00000000e+00 1.23062223e-01 1.79505134e-01]\n",
      " [0.00000000e+00 1.26606073e-01 1.26606073e-01]\n",
      " [0.00000000e+00 1.17630698e-01 1.31575219e-01]\n",
      " [0.00000000e+00 7.71355005e-02 7.71355005e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.55900977e-02 8.01953287e-02]\n",
      " [1.11022302e-16 1.11022302e-16 7.12502637e-02]\n",
      " [0.00000000e+00 0.00000000e+00 2.47617980e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.66769699e-02 1.28897533e-01]]\n",
      "\n",
      "Let's varify visually that the found nearest neighbours make sense.\n",
      "\n",
      "Indeces of elements from test for visual validation [0, 1]\n",
      "\n",
      "Elements themselves as sparse vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SparseVector(20, {2: 2.2756, 3: 1.6912, 6: 2.6478, 8: 1.6822, 11: 2.1647, 14: 1.1739, 18: 1.6747}),\n",
       " SparseVector(20, {5: 2.0771, 10: 1.8866, 11: 2.1647, 14: 1.1739, 19: 2.0622})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elements from initial dataset which were found as closest neighbours of [0, 1] element(s) from test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SparseVector(20, {2: 2.2756, 3: 1.6912, 6: 2.6478, 8: 1.6822, 11: 2.1647, 14: 1.1739, 18: 1.6747}),\n",
       " SparseVector(20, {2: 1.1378, 6: 2.6478, 8: 1.6822, 11: 2.1647, 12: 0.816, 18: 1.6747}),\n",
       " SparseVector(20, {1: 1.3631, 2: 2.2756, 6: 2.6478, 8: 1.6822, 11: 2.1647}),\n",
       " SparseVector(20, {5: 2.0771, 10: 1.8866, 11: 2.1647, 14: 1.1739, 19: 2.0622}),\n",
       " SparseVector(20, {10: 1.8866, 11: 2.1647, 14: 1.1739, 19: 2.0622}),\n",
       " SparseVector(20, {10: 1.8866, 11: 2.1647, 14: 1.1739, 19: 2.0622})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_best_estimator_ds = tfidf.limit(10).select('features').rdd.flatMap(lambda x: x).collect()\n",
    "distances, indices = clf.predict(test_best_estimator_ds)\n",
    "test_best_estimator_array = np.array(test_best_estimator_ds)\n",
    "print(\"Test dataset\")\n",
    "display(test_best_estimator_ds)\n",
    "print(\"\\nIndices of {0} nearest neighbours predicted with LSHF\".format(n_neighbors))\n",
    "print(indices)\n",
    "print(\"\\nDistances from each of {0} nearest neighbours predicted with LSHF\".format(n_neighbors))\n",
    "print(distances)\n",
    "\n",
    "print(\"\\nLet's varify visually that the found nearest neighbours make sense.\")\n",
    "check_test_element_indeces = [0,1]\n",
    "print(\"\\nIndeces of elements from test for visual validation\", check_test_element_indeces)\n",
    "print(\"\\nElements themselves as sparse vectors\") \n",
    "display(list(test_best_estimator_ds[i] for i in check_test_element_indeces))\n",
    "print(\"\\nElements from initial dataset which were found as closest neighbours of {0} element(s) from test\".\n",
    "      format(check_test_element_indeces))\n",
    "unfold_indeces_nearest_nbrs = indices[check_test_element_indeces].reshape(1, n_neighbors*len(check_test_element_indeces))[0]\n",
    "display(list(dataset[i] for i in unfold_indeces_nearest_nbrs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
